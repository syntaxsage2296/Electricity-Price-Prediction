{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "PREPROCESSED_DIR = os.path.join(BASE_DIR, \"../data/preprocessed\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"../data/processed\")\n",
    "VISUALS_DIRS = os.path.join(BASE_DIR, \"..\", \"visuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories():\n",
    "    \"\"\"Create necessary directories if they don't exist.\"\"\"\n",
    "    data_dir = PREPROCESSED_DIR\n",
    "    output_dir = PROCESSED_DIR\n",
    "    visuals_dirs = VISUALS_DIRS\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(visuals_dirs, exist_ok=True)\n",
    "    return data_dir, output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(data_dir):\n",
    "    \"\"\"Load preprocessed datasets from CSV files.\"\"\"\n",
    "    files = {\n",
    "        \"price\": \"preprocessed_cleaned_Day-ahead_prices_202301010000_202503050000_Hour.csv\",\n",
    "        \"actual_consumption\": \"preprocessed_cleaned_Actual_consumption_202301010000_202503050000_Quarterhour.csv\",\n",
    "        \"forecast_consumption\": \"preprocessed_cleaned_Forecasted_consumption_202301010000_202503050000_Quarterhour.csv\",\n",
    "        \"actual_generation\": \"preprocessed_cleaned_Actual_generation_202301010000_202503050000_Quarterhour.csv\",\n",
    "        \"forecast_generation\": \"preprocessed_cleaned_Forecasted_generation_Day-Ahead_202301010000_202503050000_Hour_Quarterhour.csv\",\n",
    "        \"cross_border_flows\": \"preprocessed_cleaned_Cross-border_physical_flows_202301010000_202503050000_Quarterhour.csv\",\n",
    "        \"scheduled_exchanges\": \"preprocessed_cleaned_Scheduled_commercial_exchanges_202301010000_202503050000_Quarterhour.csv\",\n",
    "    }\n",
    "    \n",
    "    dfs = {key: pd.read_csv(os.path.join(data_dir, file), delimiter=\",\", low_memory=False) for key, file in files.items()}\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(dfs):\n",
    "    \"\"\"Strip spaces and special characters from column names.\"\"\"\n",
    "    for df in dfs.values():\n",
    "        df.columns = df.columns.str.strip().str.replace(r\"[^\\x00-\\x7F]+\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dfs):\n",
    "    \"\"\"Convert '-' to NaN and ensure numeric columns.\"\"\"\n",
    "    for df in dfs.values():\n",
    "        df.replace(\"-\", np.nan, inplace=True)\n",
    "        df.infer_objects(copy=False)\n",
    "        df[df.columns.difference([\"Start date\"])] = df[df.columns.difference([\"Start date\"])].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_price(df_price):\n",
    "    \"\"\"Calculate average price per MWh.\"\"\"\n",
    "    price_columns = [col for col in df_price.columns if \"/MWh\" in col]\n",
    "    if not price_columns:\n",
    "        raise KeyError(\"⚠ No columns with '/MWh' found for price data!\")\n",
    "    df_price[\"Average_Price_€/MWh\"] = df_price[price_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(dfs):\n",
    "    \"\"\"Merge datasets on 'Start date' column.\"\"\"\n",
    "    df = dfs[\"price\"]\n",
    "    for key, data in dfs.items():\n",
    "        if key != \"price\":\n",
    "            df = df.merge(data, on=\"Start date\", how=\"inner\", suffixes=(\"\", f\"_{key}\"))\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"Add rolling averages, lag features, and volatility measures.\"\"\"\n",
    "    df[\"Rolling_Mean_24h\"] = df[\"Average_Price_€/MWh\"].rolling(window=24, min_periods=1).mean()\n",
    "    df[\"Rolling_Mean_7d\"] = df[\"Average_Price_€/MWh\"].rolling(window=24*7, min_periods=1).mean()\n",
    "    df[\"Price_Diff\"] = df[\"Average_Price_€/MWh\"].diff()\n",
    "    df[\"Lag_1h\"] = df[\"Average_Price_€/MWh\"].shift(1)\n",
    "    df[\"Lag_24h\"] = df[\"Average_Price_€/MWh\"].shift(24)\n",
    "    df[\"Volatility_24h\"] = df[\"Average_Price_€/MWh\"].rolling(window=24, min_periods=1).std()\n",
    "    df[\"Price_Change_1h\"] = df[\"Average_Price_€/MWh\"].pct_change() * 100\n",
    "    df[\"Price_Change_24h\"] = df[\"Average_Price_€/MWh\"].pct_change(24) * 100\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(df, output_dir):\n",
    "    \"\"\"Save processed data in different time resolutions.\"\"\"\n",
    "    \n",
    "    if \"Start date\" not in df.columns:\n",
    "        raise KeyError(\"⚠ 'Start date' column is missing after processing!\")\n",
    "\n",
    "    # Ensure 'Start date' is a datetime type\n",
    "    df[\"Start date\"] = pd.to_datetime(df[\"Start date\"], errors=\"coerce\")\n",
    "    \n",
    "    # Drop rows where 'Start date' could not be converted\n",
    "    df = df.dropna(subset=[\"Start date\"])\n",
    "\n",
    "    # Set index for resampling\n",
    "    df.set_index(\"Start date\", inplace=True)\n",
    "\n",
    "    # Now resample and save\n",
    "    df.resample(\"H\").mean().to_csv(os.path.join(output_dir, \"processed_hourly_data.csv\"), sep=\",\")\n",
    "    df.resample(\"D\").mean().to_csv(os.path.join(output_dir, \"processed_daily_data.csv\"), sep=\",\")\n",
    "    df.resample(\"W\").mean().to_csv(os.path.join(output_dir, \"processed_weekly_data.csv\"), sep=\",\")\n",
    "\n",
    "    print(\"✅ Processed data saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_19804\\1655499764.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(\"-\", np.nan, inplace=True)\n",
      "C:\\Users\\Elite\\AppData\\Local\\Temp\\ipykernel_19804\\759571360.py:17: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df.resample(\"H\").mean().to_csv(os.path.join(output_dir, \"processed_hourly_data.csv\"), sep=\",\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run data processing pipeline.\"\"\"\n",
    "    data_dir, output_dir = setup_directories()\n",
    "    dfs = load_datasets(data_dir)\n",
    "    clean_column_names(dfs)\n",
    "    preprocess_data(dfs)\n",
    "    compute_average_price(dfs[\"price\"])\n",
    "    df_merged = merge_datasets(dfs)\n",
    "    df_final = feature_engineering(df_merged)\n",
    "    save_processed_data(df_final, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
